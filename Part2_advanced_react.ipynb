{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/Autonomic_agents/blob/main/Part2_advanced_react.ipynb",
      "authorship_tag": "ABX9TyNrRzCRao1cefx/j5NaxppQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Autonomic_agents/blob/main/Part2_advanced_react.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will develop advanced react application.\n",
        "There are three language models.\n",
        "There are two search models.\n",
        "There are two creating image models."
      ],
      "metadata": {
        "id": "gCGaFdBXrZlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements.txt**"
      ],
      "metadata": {
        "id": "0hQyZfwFrd8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch requirements.txt\n",
        "!echo langchain >> requirements.txt\n",
        "!echo langchain-openai >> requirements.txt\n",
        "!echo langchain-google-genai >> requirements.txt\n",
        "!echo langchainhub >> requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo duckduckgo-search >> requirements.txt\n",
        "!echo anthropic >> requirements.txt\n",
        "!echo beautifulsoup4 >> requirements.txt\n",
        "!echo autogenstudio >> requirements.txt\n",
        "!echo crewai >> requirements.txt"
      ],
      "metadata": {
        "id": "dCwVLDEhrf1v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**terminal / bash komutu**"
      ],
      "metadata": {
        "id": "hHF5DREXrh1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC_dHXfEqwXj",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5484ea32-c6ff-4bd5-a63f-497cf6e2a5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-openai (from -r requirements.txt (line 2))\n",
            "  Downloading langchain_openai-0.1.7-py3-none-any.whl (34 kB)\n",
            "Collecting langchain-google-genai (from -r requirements.txt (line 3))\n",
            "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl (31 kB)\n",
            "Collecting langchainhub (from -r requirements.txt (line 4))\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Collecting python-dotenv (from -r requirements.txt (line 5))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting streamlit (from -r requirements.txt (line 6))\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting duckduckgo-search (from -r requirements.txt (line 7))\n",
            "  Downloading duckduckgo_search-6.1.0-py3-none-any.whl (23 kB)\n",
            "Collecting anthropic (from -r requirements.txt (line 8))\n",
            "  Downloading anthropic-0.25.9-py3-none-any.whl (871 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.1/871.1 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.12.3)\n",
            "Collecting autogenstudio (from -r requirements.txt (line 10))\n",
            "  Downloading autogenstudio-0.0.56-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crewai (from -r requirements.txt (line 11))\n",
            "  Downloading crewai-0.30.11-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 1)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain->-r requirements.txt (line 1))\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load_tools is duckduckgo search method.\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.chat_models import ChatAnthropic\n",
        "from langchain import hub\n",
        "from langchain_community.callbacks import StreamlitCallbackHandler\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "import streamlit as st\n",
        "import os\n",
        "import customtools\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "#my_key_openai = os.getenv(\"openai_apikey\")\n",
        "#my_key_google = os.getenv(\"google_apikey\")\n",
        "#my_key_anthropic = os.getenv(\"anthropic_apikey\")\n",
        "#os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"tavily_apikey\")\n",
        "\n",
        "my_key_openai=\"---\"\n",
        "my_key_google=\"---\"\n",
        "my_key_anthropic=\"---\"\n",
        "os.environ[\"TAVILY_API_KEY\"]=\"----\"\n",
        "\n",
        "llm_gemini = ChatGoogleGenerativeAI(google_api_key=my_key_google, model=\"gemini-pro\")\n",
        "llm_gpt = ChatOpenAI(api_key=my_key_openai, model=\"gpt-4-0125-preview\", temperature=0, streaming=True)\n",
        "llm_claude = ChatAnthropic(anthropic_api_key=my_key_anthropic, model_name=\"claude-2.1\")\n",
        "\n",
        "#System prompt, we call system prompt from langchain hub.\n",
        "agent_prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "st.set_page_config(page_title=\"ReAct Ajan ile Sohbet Etkileşimi\")\n",
        "#st.image(image=\"./img/ai_agent_banner.png\")\n",
        "st.title(\"ReAct Ajan ile Sohbet Etkileşimi\")\n",
        "st.divider()\n",
        "\n",
        "st.sidebar.header(\"Ajan Konfigrasyonu\") # thanks to sidebar, bar will be created on the left side.\n",
        "st.sidebar.divider()\n",
        "selected_llm = st.sidebar.radio(label=\"Dil Modeli Seçiniz\", options=[\"GPT-4\",\"Gemini Pro\", \"Claude 2.1\"])\n",
        "st.sidebar.divider()\n",
        "selected_search_engine = st.sidebar.radio(label=\"Arama Motoru Seçiniz\",options=[\"DuckDuckGo\", \"Tavily\"], index=1)\n",
        "st.sidebar.divider()\n",
        "selected_image_generator = st.sidebar.radio(label=\"Resim Üretim Modelini Seçiniz\",options=[\"Stable Diffusion XL\",\"DALL-E 3\"])\n",
        "st.sidebar.divider()\n",
        "selected_web_scraper = st.sidebar.radio(label=\"Web Kazıma Aracı Seçiniz\", options=[\"BeautifulSoup\"])\n",
        "st.sidebar.divider()\n",
        "turkish_sensitivity = st.sidebar.checkbox(label=\"Türkçe Yanıta Zorla\",value=True)\n",
        "st.sidebar.divider()\n",
        "reset_chat_btn = st.sidebar.button(label=\"Sohbeti Geçmişini sıfırla\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IBzcx2x2r8Dl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}