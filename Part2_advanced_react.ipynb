{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/kmk4444/Autonomic_agents/blob/main/Part2_advanced_react.ipynb",
      "authorship_tag": "ABX9TyMDvcYstV+5iSLotbQHT3cO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Autonomic_agents/blob/main/Part2_advanced_react.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will develop advanced react application.\n",
        "There are three language models.\n",
        "There are two search models.\n",
        "There are two creating image models."
      ],
      "metadata": {
        "id": "gCGaFdBXrZlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements.txt**"
      ],
      "metadata": {
        "id": "0hQyZfwFrd8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch requirements.txt\n",
        "!echo langchain >> requirements.txt\n",
        "!echo langchain-openai >> requirements.txt\n",
        "!echo langchain-google-genai >> requirements.txt\n",
        "!echo langchainhub >> requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo duckduckgo-search >> requirements.txt\n",
        "!echo anthropic >> requirements.txt\n",
        "!echo beautifulsoup4 >> requirements.txt\n",
        "!echo autogenstudio >> requirements.txt\n",
        "!echo crewai >> requirements.txt"
      ],
      "metadata": {
        "id": "dCwVLDEhrf1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**terminal / bash komutu**"
      ],
      "metadata": {
        "id": "hHF5DREXrh1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC_dHXfEqwXj"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile custom.py\n",
        "\n",
        "from langchain.agents import Tool # It is the most important package\n",
        "from openai import OpenAI #for dalle3\n",
        "from bs4 import BeautifulSoup # web scraping\n",
        "from io import BytesIO # image processing\n",
        "import base64 # image processing\n",
        "import requests # request for remote server\n",
        "from datetime import datetime # picture name\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "#my_key_openai = os.getenv(\"openai_apikey\")\n",
        "#my_key_stabilityai = os.getenv(\"stabilityai_apikey\")\n",
        "\n",
        "my_key_openai=\"---\"\n",
        "my_key_stabilityai=\"----\"\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=my_key_openai\n",
        ")\n",
        "\n",
        "#SDXL\n",
        "#DALLE3\n",
        "#Bsoup\n",
        "#Method->Tool\n",
        "\n",
        "def generate_image_with_dalle(prompt):\n",
        "\n",
        "  AI_Response = client.images.generate(\n",
        "      model=\"dall-e-3\",\n",
        "      size=\"1024x1024\",\n",
        "      quality=\"hd\",\n",
        "      n=1, # the number of picture\n",
        "      response_format = \"url\", #answer will be url\n",
        "      prompt=prompt\n",
        "  )\n",
        "\n",
        "  image_url = AI_Response.data[0].url # we arranged answer of chatbot\n",
        "\n",
        "  response = requests.get(image_url) # dowloand picture\n",
        "  image_bytes=BytesIO(response.content) # we assign content of picture to image_bytes using BytesIO\n",
        "\n",
        "\n",
        "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # open filepath\n",
        "  filepath = f\"/content/sample_data/generated_image_{timestamp}.png\" # write file inside of filepath\n",
        "\n",
        "  #if not os.path.exists(\"./img\"):\n",
        "  #    os.makedirs(\"./img\")\n",
        "\n",
        "  with open(filepath,\"wb\") as file:\n",
        "    file.write(image_bytes.getbuffer())\n",
        "\n",
        "  return f'<a href=\"{filepath}\">Resminiz Burada</a>' # it creates a link as html format\n",
        "\n"
      ],
      "metadata": {
        "id": "Pj0jDfAThTFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "#load_tools is duckduckgo search method.\n",
        "from langchain.agents import AgentExecutor, create_react_agent, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.chat_models import ChatAnthropic\n",
        "from langchain import hub\n",
        "from langchain_community.callbacks import StreamlitCallbackHandler # it shows agent processes on screen (reasoning and acting)\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "import streamlit as st\n",
        "import os\n",
        "#import customtools\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "#my_key_openai = os.getenv(\"openai_apikey\")\n",
        "#my_key_google = os.getenv(\"google_apikey\")\n",
        "#my_key_anthropic = os.getenv(\"anthropic_apikey\")\n",
        "#os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"tavily_apikey\")\n",
        "\n",
        "my_key_openai=\"--\"\n",
        "my_key_google=\"---\"\n",
        "my_key_anthropic=\"---\"\n",
        "os.environ[\"TAVILY_API_KEY\"]=\"----\"\n",
        "\n",
        "#llm_gemini = ChatGoogleGenerativeAI(google_api_key=my_key_google, model=\"gemini-1.0-pro\") ERROR!\n",
        "llm_gpt = ChatOpenAI(api_key=my_key_openai, model=\"gpt-4-0125-preview\", temperature=0, streaming=True)\n",
        "llm_claude = ChatAnthropic(anthropic_api_key=my_key_anthropic, model_name=\"claude-2.1\")\n",
        "\n",
        "#System prompt, we call system prompt from langchain hub.\n",
        "agent_prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "def configure_agent(selected_llm, selected_search_engine, selected_image_generator=\"\"):\n",
        "    #\n",
        "    if selected_llm == \"GPT-4\":\n",
        "        llm = llm_gpt\n",
        "    elif selected_llm == \"Gemini Pro\":\n",
        "        llm = llm_gemini\n",
        "    elif selected_llm == \"Claude 2.1\":\n",
        "        llm = llm_claude\n",
        "\n",
        "    if selected_search_engine ==\"DuckDuckGo\":\n",
        "      tools = load_tools([\"ddg-search\"]) # we call load_tools method to run duckduckgo\n",
        "    elif selected_search_engine == \"Tavily\":\n",
        "      tools = [TavilySearchResults(max_results=1)] # we reach one best solution. you can increase max_results but sometimes it can be error because of langchain mistake.\n",
        "\n",
        "\n",
        "    agent = create_react_agent(llm=llm, tools=tools, prompt=agent_prompt) # we described agent\n",
        "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose = True) #we need executor to run agent\n",
        "    #verbose=True provides colorful output.\n",
        "\n",
        "    return agent_executor\n",
        "\n",
        "\n",
        "#Interface\n",
        "\n",
        "st.set_page_config(page_title=\"ReAct Ajan ile Sohbet Etkileimi\")\n",
        "#st.image(image=\"./img/ai_agent_banner.png\")\n",
        "st.title(\"ReAct Ajan ile Sohbet Etkileimi\")\n",
        "st.divider()\n",
        "\n",
        "st.sidebar.header(\"Ajan Konfigrasyonu\") # thanks to sidebar, bar will be created on the left side.\n",
        "st.sidebar.divider()\n",
        "selected_llm = st.sidebar.radio(label=\"Dil Modeli Se癟iniz\", options=[\"GPT-4\",\"Gemini Pro\", \"Claude 2.1\"])\n",
        "st.sidebar.divider()\n",
        "selected_search_engine = st.sidebar.radio(label=\"Arama Motoru Se癟iniz\",options=[\"DuckDuckGo\", \"Tavily\"], index=1)\n",
        "st.sidebar.divider()\n",
        "selected_image_generator = st.sidebar.radio(label=\"Resim retim Modelini Se癟iniz\",options=[\"Stable Diffusion XL\",\"DALL-E 3\"])\n",
        "st.sidebar.divider()\n",
        "selected_web_scraper = st.sidebar.radio(label=\"Web Kaz覺ma Arac覺 Se癟iniz\", options=[\"BeautifulSoup\"])\n",
        "st.sidebar.divider()\n",
        "turkish_sensitivity = st.sidebar.checkbox(label=\"T羹rk癟e Yan覺ta Zorla\",value=True)\n",
        "st.sidebar.divider()\n",
        "reset_chat_btn = st.sidebar.button(label=\"Sohbeti Ge癟miini s覺f覺rla\")\n",
        "\n",
        "\n",
        "# We want to save old messages on the screen.\n",
        "# When we run program first time, program will create empty message list.\n",
        "if \"messages\" not in st.session_state: # if messages is not created, we'll create Session State message list.\n",
        "  st.session_state.messages = []\n",
        "  #st.session_state.messages.append({\"role\":\"system\", \"content\":\"Sen yard覺msever bir asistans覺n\"}) # We append system default prompt. (This is default first message)\n",
        "\n",
        "\n",
        "#we will show our message on the chat window.\n",
        "for message in st.session_state.messages:\n",
        "  with st.chat_message(message[\"role\"]):# it provides to show icon for role,asisstant and system.\n",
        "    st.markdown(message[\"content\"])# it provides to show icon for role,asisstant and system.\n",
        "\n",
        "#if user click prompt button\n",
        "if prompt := st.chat_input(placeholder=\"Mesaj覺n覺z覺 yaz覺n覺z\"):\n",
        "  st.chat_message(\"user\").write(prompt) # thanks to chat_message, user prompt will be shown on the screen.\n",
        "\n",
        "  # if turkish is selected, we add a little sentence to user prompt.\n",
        "  if turkish_sensitivity:\n",
        "    st.session_state.messages.append({\"role\":\"user\", \"content\": prompt + \"Bu soruyu T羹rk癟e yan覺tla\"})\n",
        "  else:\n",
        "      st.session_state.messages.append({\"role\":\"user\", \"content\": prompt})\n",
        "\n",
        "  #agent create an answer.\n",
        "  with st.chat_message(\"assistant\"):\n",
        "    st.info(\" D羹羹nce Zinciri 襤letiliyor...\")\n",
        "\n",
        "    # it shows all process of agent;that is to say, it shows terminal screen on your web page.\n",
        "    st_callback = StreamlitCallbackHandler(st.container())\n",
        "    # we start agent accordingly our prompt, engine and image.\n",
        "    executor = configure_agent(selected_llm=selected_llm, selected_search_engine=selected_search_engine, selected_image_generator=selected_image_generator)\n",
        "\n",
        "    # LLM create an answer using invoke method.\n",
        "   # callbacks provide better user friend demonstration of process of agent.\n",
        "    AI_Response = executor.invoke(\n",
        "        {\"input\": st.session_state.messages}, {\"callbacks\": [st_callback]}, # Eski mesajlar覺da dikkate alarak cevap verecek. we used st.session_state.messages instead of prompt because we want to answer from gpt using all historical messages and new message.\n",
        "        handle_parsing_errors=True #handle_parsing_errors=True means when agents work together, there can be error. Thanks to that, program ignores these errors.\n",
        "        )\n",
        "    #unsafe_allow_html=True, we can click link if chatbot show a webpage or we can see graph or picture\n",
        "    #AI_Response[\"output\"] we select output keyword of AI_response array.\n",
        "    st.markdown(AI_Response[\"output\"], unsafe_allow_html=True)\n",
        "\n",
        "    st.session_state.messages.append({\"role\":\"assistant\", \"content\": AI_Response[\"output\"]})\n",
        "\n",
        "#we deleted history chat\n",
        "if reset_chat_btn:\n",
        "    st.session_state.messages = []\n",
        "    st.toast(\"Sohbet ge癟mii s覺f覺rland覺!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBzcx2x2r8Dl",
        "outputId": "bfe160ee-a5ca-4620-ae31-bfe2c371eeb3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n",
        "!streamlit run /content/app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EnrE8GSjpEQ",
        "outputId": "18b68e6f-9256-49f6-e351-0655c7f72cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.556s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.583s\n",
            "your url is: https://every-clubs-begin.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjCaunNZy5GD",
        "outputId": "ec87d0e7-6b31-4694-fbe0-6f236ee25e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit, version 1.34.0\n"
          ]
        }
      ]
    }
  ]
}