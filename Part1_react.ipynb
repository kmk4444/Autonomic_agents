{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8n1i+2MzJrxF2Wrfh0wc1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmk4444/Autonomic_agents/blob/main/Part1_react.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReACT**\n",
        "- ReACT means Reason and Act.\n",
        "- Reason is creating an idea.\n",
        "- Act is action.\n",
        "- Reason: Chain of Thought Prompting\n",
        "- Act:Action Plan Generation\n",
        "- ReAct was developed by Google Research and Princeton University\n",
        "- There are different tools, for example, searching web, calculate, rag, draw a picture.\n",
        "\n",
        "https://www.width.ai/post/react-prompting"
      ],
      "metadata": {
        "id": "Y9C47YbdCSQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements.txt**"
      ],
      "metadata": {
        "id": "wek6CxUreRIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch requirements.txt\n",
        "!echo langchain >> requirements.txt\n",
        "!echo langchain-openai >> requirements.txt\n",
        "!echo langchain-google-genai >> requirements.txt\n",
        "!echo langchainhub >> requirements.txt\n",
        "!echo python-dotenv >> requirements.txt\n",
        "!echo streamlit >> requirements.txt\n",
        "!echo anthropic >> requirements.txt\n",
        "!echo beautifulsoup4 >> requirements.txt\n",
        "!echo autogenstudio >> requirements.txt\n",
        "!echo crewai >> requirements.txt"
      ],
      "metadata": {
        "id": "RGpgZINjeIQk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**terminal / bash komutu**"
      ],
      "metadata": {
        "id": "uNUQFMCkeobP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "e3n8wxRtepN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pvpGzh-SkfeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05e7f58c-854b-4639-f845-cf67e230e20b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the date of the next local elections in Turkey, I need to search for it using a reliable source. I will use the tavily_search_results_json to find this information.\n",
            "Action: tavily_search_results_json\n",
            "Action Input: Türkiye'de bir sonraki yerel seçimlerin tarihi\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://tr.wikipedia.org/wiki/Bir_sonraki_Türkiye_yerel_seçimleri', 'content': \"Liderlik tarihi 15 Ekim 2023 6 Temmuz 1997 27 Nisan 2024 ... %5,70 %4,99 %3,76 Bir sonraki Türkiye yerel seçimleri, Türkiye'deki yerel yönetimlerin belirlenmesi için 2029 yılında yapılması beklenen yerel ... Enflasyon nedeniyle Türkiye'de ucuz ürün satışlarında uzun kuyruklar görülmeye ve belirli alanlarda ürün yokluğu ...\"}]\u001b[0m\u001b[32;1m\u001b[1;3mThe information provided in the search result seems to contain various dates, but the specific date for the next local elections in Turkey is mentioned as expected to occur in 2029. The other dates mentioned in the snippet seem to be unrelated to the election date and might confuse the context. Therefore, the answer to the question is found in the snippet, albeit amidst some unrelated details.\n",
            "Final Answer: Bir sonraki Türkiye yerel seçimleri, 2029 yılında yapılması bekleniyor.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "****************************************************************************************************\n",
            "Sorunuz Şuydu: Türkiye'de bir sonraki yerel seçimler hangi tarihte gerçekleştirilecek? Cevabı bulduktan sonra yanıtını Türkçe yaz.\n",
            "****************************************************************************************************\n",
            "Yanıt şu: Bir sonraki Türkiye yerel seçimleri, 2029 yılında yapılması bekleniyor.\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "#load_dotenv()\n",
        "\n",
        "#os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"tavily_apikey\")\n",
        "#my_key_openai = os.getenv(\"openai_apikey\")\n",
        "#my_key_google = os.getenv(\"google_apikey\")\n",
        "\n",
        "#API KEY\n",
        "my_key_google=\"---\"\n",
        "my_key_openai=\"---\"\n",
        "os.environ[\"TAVILY_API_KEY\"]=\"----\"\n",
        "\n",
        "# CREATING A MODEL\n",
        "llm_gemini = ChatGoogleGenerativeAI(google_api_key=my_key_google, model=\"gemini-pro\")\n",
        "llm_gpt = ChatOpenAI(api_key=my_key_openai, model=\"gpt-4-0125-preview\")\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)] # we select tools in this line. we selected just one tool.\n",
        "\n",
        "#prompt = hub.pull(\"emreyz/react-turkce\")\n",
        "prompt = hub.pull(\"hwchase17/react\")# agent needs a system prompt. we reached a system prompt by hub\n",
        "#we can save our prompt langchain hub platform. Then, we call these prompts easily.\n",
        "\n",
        "llm = llm_gpt # We prefer chatgpt but you can choose llm_gemini\n",
        "\n",
        "agent = create_react_agent(llm, tools, prompt) # we create an agent. we described llm, tools and our system prompt.\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # we create an agent executor.\n",
        "#we described agent, tools and verbose. If verbose is true, we will see colurful output.\n",
        "\n",
        "result = agent_executor.invoke({\"input\": \"Türkiye'de bir sonraki yerel seçimler hangi tarihte gerçekleştirilecek? Cevabı bulduktan sonra yanıtını Türkçe yaz.\"}, handle_parsing_errors=True)\n",
        "#handle_parsing_errors=True means when agents work together, there can be error. Thanks to that, program ignores these errors.\n",
        "print(\"*\"*100)\n",
        "print(f\"Sorunuz Şuydu: {result['input']}\")\n",
        "print(\"*\"*100)\n",
        "print(f\"Yanıt şu: {result['output']}\")"
      ]
    }
  ]
}